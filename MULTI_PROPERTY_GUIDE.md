# Multi-Property GNN Prediction Guide

This guide explains how to train and use GNN models that predict **multiple material properties simultaneously** instead of just formation energy.

---

## ğŸŒŸ New Capabilities

Your GNN can now predict **8 different properties** at once:

| Property | Unit | Description |
|----------|------|-------------|
| **Formation Energy** | eV/atom | Stability relative to elements |
| **Energy Above Hull** | eV/atom | Stability relative to decomposition |
| **Band Gap** | eV | Electronic band gap (0 = metal) |
| **Density** | g/cmÂ³ | Mass density |
| **Volume** | Å³/atom | Atomic volume |
| **Bulk Modulus** | GPa | Resistance to compression |
| **Shear Modulus** | GPa | Resistance to shear |
| **Total Magnetization** | Î¼B | Magnetic moment |

---

## ğŸ“Š Advantages of Multi-Task Learning

**Why predict multiple properties together?**

1. **Shared Learning**: Model learns general materials patterns useful for all properties
2. **Better Accuracy**: Related properties inform each other (e.g., density helps predict modulus)
3. **Efficiency**: Train one model instead of 8 separate models
4. **Less Data**: Multi-task learning regularizes and can work with less data per property

---

## ğŸš€ Quick Start

### Step 1: Collect Multi-Property Data

```python
from gnn_data_collection import fetch_materials_data
from gnn_data_collection_multitask import convert_to_multitask_graphs

# Fetch data from Materials Project
df = fetch_materials_data(
    api_key="your-api-key",
    elements=["Fe", "Ni"],
    max_materials=2000,
    metallic_only=False  # Get variety for band gap
)

# Convert to multi-task graphs
properties_to_predict = [
    'formation_energy_per_atom',
    'band_gap',
    'density'
]

graphs = convert_to_multitask_graphs(
    df,
    target_properties=properties_to_predict,
    use_calphad=True  # Recommended for better accuracy
)
```

### Step 2: Train Multi-Task Model

```python
from gnn_model_multitask import CGCNN_MultiTask_CALPHAD
from gnn_train_multitask import MultiTaskGNNTrainer
from torch_geometric.loader import DataLoader

# Split data (80/10/10)
train_size = int(0.8 * len(graphs))
val_size = int(0.1 * len(graphs))

train_graphs = graphs[:train_size]
val_graphs = graphs[train_size:train_size+val_size]
test_graphs = graphs[train_size+val_size:]

# Create data loaders
train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)
val_loader = DataLoader(val_graphs, batch_size=32)
test_loader = DataLoader(test_graphs, batch_size=32)

# Create multi-task model
model = CGCNN_MultiTask_CALPHAD(
    properties=properties_to_predict,
    hidden_dim=128,
    n_conv=3,
    n_hidden=2
)

# Train
trainer = MultiTaskGNNTrainer(
    model=model,
    properties=properties_to_predict,
    learning_rate=0.001
)

history = trainer.train(
    train_loader=train_loader,
    val_loader=val_loader,
    epochs=100,
    patience=20
)

# Plot training curves
trainer.plot_training_history('multitask_training.png')
```

### Step 3: Make Predictions

```python
from streamlit_prediction_utils import load_model_and_predict
from pymatgen.core import Structure, Lattice

# Create or load structure
lattice = Lattice.cubic(3.6)
structure = Structure(
    lattice,
    ["Fe", "Ni", "Fe", "Ni"],
    [[0,0,0], [0.5,0.5,0], [0.5,0,0.5], [0,0.5,0.5]]
)

# Predict all properties at once
predictions, is_multitask, uses_calphad = load_model_and_predict(
    structure,
    checkpoint_path="checkpoints/best_model_multitask.pt"
)

# Display results
print("Predictions:")
for prop, value in predictions.items():
    print(f"  {prop}: {value:.4f}")

# Example output:
# Predictions:
#   formation_energy_per_atom: -0.4521 eV/atom
#   band_gap: 0.0234 eV  (metallic!)
#   density: 8.423 g/cmÂ³
```

---

## ğŸ“‹ Available Properties in Materials Project

Not all materials have all properties. Check coverage before training:

```python
from gnn_data_collection_multitask import print_property_summary

# Fetch data
df = fetch_materials_data(...)

# Check what's available
print_property_summary(df)
```

**Example output:**
```
Property Coverage Summary
======================================================================
âœ… Formation Energy (eV/atom)              1847/2000 (92.4%)
âœ… Band Gap (eV)                          1998/2000 (99.9%)
âœ… Density (g/cmÂ³)                        2000/2000 (100.0%)
âš ï¸  Bulk Modulus (GPa)                     623/2000 (31.2%)
âŒ Shear Modulus (GPa)                     591/2000 (29.6%)
```

**Recommendation:** Only include properties with >80% coverage for reliable training.

---

## ğŸ¯ Choosing Properties to Predict

### Good Combinations

**Materials Discovery** (Stability + Electronic + Mechanical):
```python
properties = [
    'formation_energy_per_atom',  # Stability
    'band_gap',                   # Electronic
    'density',                    # General
    'bulk_modulus'                # Mechanical (if available)
]
```

**Electronic Materials** (Focus on electronic properties):
```python
properties = [
    'formation_energy_per_atom',
    'band_gap',
    'density'
]
```

**Structural Materials** (Focus on mechanical):
```python
properties = [
    'formation_energy_per_atom',
    'density',
    'bulk_modulus',
    'shear_modulus'  # If available
]
```

**Magnetic Materials**:
```python
properties = [
    'formation_energy_per_atom',
    'band_gap',
    'total_magnetization'
]
```

---

## âš™ï¸ Model Architecture

### Standard Multi-Task Model

```python
from gnn_model_multitask import CGCNN_MultiTask

model = CGCNN_MultiTask(
    node_feature_dim=64,
    edge_feature_dim=1,
    hidden_dim=128,
    n_conv=3,
    n_hidden=2,
    properties=['formation_energy_per_atom', 'band_gap', 'density']
)
```

### CALPHAD-Enhanced Multi-Task Model (Recommended)

```python
from gnn_model_multitask import CGCNN_MultiTask_CALPHAD

model = CGCNN_MultiTask_CALPHAD(
    input_node_dim=13,      # CALPHAD features
    input_edge_dim=2,        # Distance + mixing energy
    node_feature_dim=64,
    edge_feature_dim=32,
    hidden_dim=128,
    n_conv=3,
    n_hidden=2,
    properties=['formation_energy_per_atom', 'band_gap', 'density']
)
```

**CALPHAD features improve accuracy by 10-20%!**

---

## ğŸ”¬ Training Details

### Multi-Task Loss Function

The model uses **uncertainty weighting** to automatically balance different tasks:

```
Total Loss = Î£ (loss_i / (2 * Ïƒ_iÂ²) + log(Ïƒ_i))
```

Where:
- `loss_i` = MSE for property i
- `Ïƒ_i` = Learned uncertainty for property i

**Benefits:**
- No manual loss weight tuning
- Automatically balances easier vs. harder tasks
- Focuses on properties with good data coverage

### Handling Missing Data

If a material doesn't have all properties:
- Model uses available properties for training
- Missing values (NaN) are skipped in loss calculation
- Still contributes to shared feature learning

**Example:**
- Material A: Has formation_energy, band_gap, density â†’ Uses all 3
- Material B: Only has formation_energy, density â†’ Uses 2, skips band_gap
- Both materials still improve the shared encoder!

---

## ğŸ“ˆ Interpreting Results

### Formation Energy
- **< -0.3 eV/atom**: Highly stable âœ…
- **-0.3 to 0**: Stable âœ“
- **0 to 0.2**: Marginally unstable âš ï¸
- **> 0.2**: Unstable âŒ

### Band Gap
- **< 0.1 eV**: Metallic âš¡
- **0.1-2.0 eV**: Semiconductor ğŸ”Œ
- **> 2.0 eV**: Insulator ğŸ”’

### Density
- **< 3.0 g/cmÂ³**: Lightweight ğŸª¶
- **3-10 g/cmÂ³**: Medium weight âš–ï¸
- **> 10 g/cmÂ³**: Heavyweight âš“

### Bulk/Shear Modulus
- **> 200 GPa**: Very stiff ğŸ’
- **100-200 GPa**: Stiff ğŸ’ª
- **50-100 GPa**: Moderate âš–ï¸
- **< 50 GPa**: Soft ğŸ¥

---

## ğŸ¨ Streamlit Integration

The prediction utilities automatically detect multi-task models and display all properties:

```python
from streamlit_prediction_utils import load_model_and_predict, display_predictions

# In your Streamlit app
predictions, is_multitask, uses_calphad = load_model_and_predict(
    structure,
    checkpoint_path="checkpoints/best_model_multitask.pt",
    node_dim=64,
    hidden_dim=128,
    n_conv=3,
    n_hidden=2
)

# Display all predictions with interpretations
display_predictions(
    predictions,
    formula=structure.composition.reduced_formula,
    composition_info="Fe50Ni50"
)
```

**Features:**
- Auto-detects single-task vs. multi-task models
- Displays all properties with proper units
- Color-coded stability indicators
- Detailed interpretations for each property
- CSV download of results

---

## ğŸ“Š Complete Training Example

```python
#!/usr/bin/env python
"""
Complete multi-task GNN training example.
Predicts formation energy, band gap, and density.
"""

import os
from dotenv import load_dotenv
from gnn_data_collection import fetch_materials_data
from gnn_data_collection_multitask import convert_to_multitask_graphs, print_property_summary
from gnn_model_multitask import CGCNN_MultiTask_CALPHAD
from gnn_train_multitask import MultiTaskGNNTrainer
from torch_geometric.loader import DataLoader
import torch

# Load API key
load_dotenv()
api_key = os.environ.get("MP_API_KEY")

# 1. Collect data
print("="*70)
print("Collecting Materials Data")
print("="*70)

df = fetch_materials_data(
    api_key=api_key,
    elements=["Fe", "Ni"],
    max_materials=2000,
    metallic_only=False
)

# Check property coverage
print_property_summary(df)

# 2. Choose properties
properties_to_predict = [
    'formation_energy_per_atom',
    'band_gap',
    'density'
]

# 3. Convert to graphs
print("\n" + "="*70)
print("Converting to Graphs")
print("="*70)

graphs = convert_to_multitask_graphs(
    df,
    target_properties=properties_to_predict,
    use_calphad=True,
    save_path="datasets/fe_ni_multitask.pkl"
)

# 4. Split data
torch.manual_seed(42)
indices = torch.randperm(len(graphs))

train_size = int(0.8 * len(graphs))
val_size = int(0.1 * len(graphs))

train_idx = indices[:train_size]
val_idx = indices[train_size:train_size+val_size]
test_idx = indices[train_size+val_size:]

train_graphs = [graphs[i] for i in train_idx]
val_graphs = [graphs[i] for i in val_idx]
test_graphs = [graphs[i] for i in test_idx]

# 5. Create loaders
train_loader = DataLoader(train_graphs, batch_size=32, shuffle=True)
val_loader = DataLoader(val_graphs, batch_size=32)
test_loader = DataLoader(test_graphs, batch_size=32)

# 6. Create model
print("\n" + "="*70)
print("Creating Multi-Task Model")
print("="*70)

model = CGCNN_MultiTask_CALPHAD(
    properties=properties_to_predict,
    hidden_dim=128,
    n_conv=3,
    n_hidden=2
)

print(f"Properties: {properties_to_predict}")
print(f"Parameters: {sum(p.numel() for p in model.parameters()):,}")

# 7. Train
print("\n" + "="*70)
print("Training")
print("="*70)

trainer = MultiTaskGNNTrainer(
    model=model,
    properties=properties_to_predict,
    learning_rate=0.001
)

history = trainer.train(
    train_loader=train_loader,
    val_loader=val_loader,
    epochs=100,
    patience=20,
    verbose=True
)

# 8. Plot results
trainer.plot_training_history('multitask_training.png')

print("\nâœ… Training complete!")
print(f"   Best epoch: {trainer.best_epoch}")
print(f"   Best val loss: {trainer.best_val_loss:.6f}")
print(f"   Model saved to: checkpoints/best_model_multitask.pt")
```

---

## ğŸ” Testing Your Model

```python
from streamlit_prediction_utils import load_model_and_predict
from pymatgen.core import Structure, Lattice

# Test on known material
lattice = Lattice.cubic(3.6)
structure = Structure(
    lattice,
    ["Fe", "Fe", "Ni", "Ni"],
    [[0,0,0], [0.5,0.5,0], [0.5,0,0.5], [0,0.5,0.5]]
)

predictions, _, _ = load_model_and_predict(
    structure,
    "checkpoints/best_model_multitask.pt"
)

print("Predictions for Fe50Ni50:")
for prop, value in predictions.items():
    print(f"  {prop}: {value:.4f}")

# Compare to Materials Project values
# Fe50Ni50 (mp-1200945):
#   Formation Energy: ~-0.45 eV/atom
#   Band Gap: ~0.0 eV (metallic)
#   Density: ~8.4 g/cmÂ³
```

---

## ğŸ“š Best Practices

1. **Start Simple**: Begin with 2-3 properties, expand later
2. **Check Coverage**: Only use properties with >80% coverage
3. **Use CALPHAD**: CALPHAD features improve all properties
4. **Large Datasets**: Multi-task learning works best with 1000+ materials
5. **Related Properties**: Choose properties that might share patterns
6. **Validate**: Test on Materials Project entries to verify accuracy

---

## ğŸš¨ Troubleshooting

**"Property X has low coverage"**
- Solution: Remove it from training or collect more data

**"Training loss not decreasing"**
- Check data quality
- Try smaller learning rate (0.0001)
- Use more epochs
- Increase model capacity (hidden_dim=256)

**"One property predicts poorly"**
- Normal - some properties are harder
- Multi-task loss automatically handles this
- May need more data for that property

**"Model predictions seem random"**
- Check training converged (loss decreased)
- Verify test set isn't too different from training
- Ensure enough data (1000+ materials minimum)

---

## ğŸ“ Summary

**You can now:**
âœ… Train models that predict multiple properties simultaneously
âœ… Use Materials Project data for 8 different properties
âœ… Automatically balance multi-task learning
âœ… Handle missing data gracefully
âœ… Get comprehensive material predictions in one forward pass

**Next steps:**
1. Collect multi-property data
2. Train multi-task model
3. Make predictions on new materials
4. Compare accuracy across properties
5. Use predictions to guide experiments!

**Happy multi-property predicting! ğŸš€**
